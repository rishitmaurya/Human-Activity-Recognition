(env) PS D:\Rishit Mtech 2nd yr project\Human Gait\Code_stuff> python .\ms_grs_bilstm\ms_grs_lstm.py
Found 210 files in dataset.
Raw windows shape: (7395, 64, 75)
Train shape: (5916, 64, 75) (5916, 7) Test shape: (1479, 64, 75) (1479, 7)
2025-10-18 16:31:20.904869: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX AVX2
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
Model: "MS_GatedResidualSkipLSTM"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to
==================================================================================================
 input_seq (InputLayer)         [(None, 64, 75)]     0           []

 downsample_2 (Lambda)          (None, 32, 75)       0           ['input_seq[0][0]']

 downsample_4 (Lambda)          (None, 16, 75)       0           ['input_seq[0][0]']

 scale0_b1_bilstm (Bidirectiona  (None, 64, 128)     71680       ['input_seq[0][0]']
 l)

 scale1_b1_bilstm (Bidirectiona  (None, 32, 128)     71680       ['downsample_2[0][0]']
 l)

 scale2_b1_bilstm (Bidirectiona  (None, 16, 128)     71680       ['downsample_4[0][0]']
 l)

 scale0_b1_lstm_proj (TimeDistr  (None, 64, 64)      8256        ['scale0_b1_bilstm[0][0]']
 ibuted)

 scale1_b1_lstm_proj (TimeDistr  (None, 32, 64)      8256        ['scale1_b1_bilstm[0][0]']
 ibuted)

 scale2_b1_lstm_proj (TimeDistr  (None, 16, 64)      8256        ['scale2_b1_bilstm[0][0]']
 ibuted)

 scale0_b1_proj_td (TimeDistrib  (None, 64, 64)      4864        ['input_seq[0][0]']
 uted)

 dropout (Dropout)              (None, 64, 64)       0           ['scale0_b1_lstm_proj[0][0]']

 scale1_b1_proj_td (TimeDistrib  (None, 32, 64)      4864        ['downsample_2[0][0]']
 uted)

 dropout_2 (Dropout)            (None, 32, 64)       0           ['scale1_b1_lstm_proj[0][0]']

 scale2_b1_proj_td (TimeDistrib  (None, 16, 64)      4864        ['downsample_4[0][0]']
 uted)

 dropout_4 (Dropout)            (None, 16, 64)       0           ['scale2_b1_lstm_proj[0][0]']

 concatenate (Concatenate)      (None, 64, 128)      0           ['scale0_b1_proj_td[0][0]',
                                                                  'dropout[0][0]']

 concatenate_2 (Concatenate)    (None, 32, 128)      0           ['scale1_b1_proj_td[0][0]',
                                                                  'dropout_2[0][0]']

 concatenate_4 (Concatenate)    (None, 16, 128)      0           ['scale2_b1_proj_td[0][0]',
                                                                  'dropout_4[0][0]']

 scale0_b1_gate (TimeDistribute  (None, 64, 64)      8256        ['concatenate[0][0]']
 d)

 scale1_b1_gate (TimeDistribute  (None, 32, 64)      8256        ['concatenate_2[0][0]']
 d)

 scale2_b1_gate (TimeDistribute  (None, 16, 64)      8256        ['concatenate_4[0][0]']
 d)

 lambda (Lambda)                (None, 64, 64)       0           ['scale0_b1_gate[0][0]']

 lambda_2 (Lambda)              (None, 32, 64)       0           ['scale1_b1_gate[0][0]']

 lambda_4 (Lambda)              (None, 16, 64)       0           ['scale2_b1_gate[0][0]']

 multiply (Multiply)            (None, 64, 64)       0           ['scale0_b1_gate[0][0]',
                                                                  'dropout[0][0]']

 multiply_1 (Multiply)          (None, 64, 64)       0           ['lambda[0][0]',
                                                                  'scale0_b1_proj_td[0][0]']

 multiply_4 (Multiply)          (None, 32, 64)       0           ['scale1_b1_gate[0][0]',
                                                                  'dropout_2[0][0]']

 multiply_5 (Multiply)          (None, 32, 64)       0           ['lambda_2[0][0]',
                                                                  'scale1_b1_proj_td[0][0]']

 multiply_8 (Multiply)          (None, 16, 64)       0           ['scale2_b1_gate[0][0]',
                                                                  'dropout_4[0][0]']

 multiply_9 (Multiply)          (None, 16, 64)       0           ['lambda_4[0][0]',
                                                                  'scale2_b1_proj_td[0][0]']

 add (Add)                      (None, 64, 64)       0           ['multiply[0][0]',
                                                                  'multiply_1[0][0]']

 add_3 (Add)                    (None, 32, 64)       0           ['multiply_4[0][0]',
                                                                  'multiply_5[0][0]']

 add_6 (Add)                    (None, 16, 64)       0           ['multiply_8[0][0]',
                                                                  'multiply_9[0][0]']

 scale0_b2_bilstm (Bidirectiona  (None, 64, 128)     66048       ['add[0][0]']
 l)

 scale1_b2_bilstm (Bidirectiona  (None, 32, 128)     66048       ['add_3[0][0]']
 l)

 scale2_b2_bilstm (Bidirectiona  (None, 16, 128)     66048       ['add_6[0][0]']
 l)

 scale0_b2_lstm_proj (TimeDistr  (None, 64, 64)      8256        ['scale0_b2_bilstm[0][0]']
 ibuted)

 scale1_b2_lstm_proj (TimeDistr  (None, 32, 64)      8256        ['scale1_b2_bilstm[0][0]']
 ibuted)

 scale2_b2_lstm_proj (TimeDistr  (None, 16, 64)      8256        ['scale2_b2_bilstm[0][0]']
 ibuted)

 scale0_b2_proj_td (TimeDistrib  (None, 64, 64)      4160        ['add[0][0]']
 uted)

 dropout_1 (Dropout)            (None, 64, 64)       0           ['scale0_b2_lstm_proj[0][0]']

 scale1_b2_proj_td (TimeDistrib  (None, 32, 64)      4160        ['add_3[0][0]']
 uted)

 dropout_3 (Dropout)            (None, 32, 64)       0           ['scale1_b2_lstm_proj[0][0]']

 scale2_b2_proj_td (TimeDistrib  (None, 16, 64)      4160        ['add_6[0][0]']
 uted)

 dropout_5 (Dropout)            (None, 16, 64)       0           ['scale2_b2_lstm_proj[0][0]']

 concatenate_1 (Concatenate)    (None, 64, 128)      0           ['scale0_b2_proj_td[0][0]',
                                                                  'dropout_1[0][0]']

 concatenate_3 (Concatenate)    (None, 32, 128)      0           ['scale1_b2_proj_td[0][0]',
                                                                  'dropout_3[0][0]']

 concatenate_5 (Concatenate)    (None, 16, 128)      0           ['scale2_b2_proj_td[0][0]',
                                                                  'dropout_5[0][0]']

 scale0_b2_gate (TimeDistribute  (None, 64, 64)      8256        ['concatenate_1[0][0]']
 d)

 scale1_b2_gate (TimeDistribute  (None, 32, 64)      8256        ['concatenate_3[0][0]']
 d)

 scale2_b2_gate (TimeDistribute  (None, 16, 64)      8256        ['concatenate_5[0][0]']
 d)

 lambda_1 (Lambda)              (None, 64, 64)       0           ['scale0_b2_gate[0][0]']

 lambda_3 (Lambda)              (None, 32, 64)       0           ['scale1_b2_gate[0][0]']

 lambda_5 (Lambda)              (None, 16, 64)       0           ['scale2_b2_gate[0][0]']

 multiply_2 (Multiply)          (None, 64, 64)       0           ['scale0_b2_gate[0][0]',
                                                                  'dropout_1[0][0]']

 multiply_3 (Multiply)          (None, 64, 64)       0           ['lambda_1[0][0]',
                                                                  'scale0_b2_proj_td[0][0]']

 multiply_6 (Multiply)          (None, 32, 64)       0           ['scale1_b2_gate[0][0]',
                                                                  'dropout_3[0][0]']

 multiply_7 (Multiply)          (None, 32, 64)       0           ['lambda_3[0][0]',
                                                                  'scale1_b2_proj_td[0][0]']

 multiply_10 (Multiply)         (None, 16, 64)       0           ['scale2_b2_gate[0][0]',
                                                                  'dropout_5[0][0]']

 multiply_11 (Multiply)         (None, 16, 64)       0           ['lambda_5[0][0]',
                                                                  'scale2_b2_proj_td[0][0]']

 add_1 (Add)                    (None, 64, 64)       0           ['multiply_2[0][0]',
                                                                  'multiply_3[0][0]']

 add_4 (Add)                    (None, 32, 64)       0           ['multiply_6[0][0]',
                                                                  'multiply_7[0][0]']

 add_7 (Add)                    (None, 16, 64)       0           ['multiply_10[0][0]',
                                                                  'multiply_11[0][0]']

 add_2 (Add)                    (None, 64, 64)       0           ['add_1[0][0]',
                                                                  'add[0][0]']

 add_5 (Add)                    (None, 32, 64)       0           ['add_4[0][0]',
                                                                  'add_3[0][0]']

 add_8 (Add)                    (None, 16, 64)       0           ['add_7[0][0]',
                                                                  'add_6[0][0]']

 scale0_pool (GlobalAveragePool  (None, 64)          0           ['add_2[0][0]']
 ing1D)

 scale1_pool (GlobalAveragePool  (None, 64)          0           ['add_5[0][0]']
 ing1D)

 scale2_pool (GlobalAveragePool  (None, 64)          0           ['add_8[0][0]']
 ing1D)

 concat_scales (Concatenate)    (None, 192)          0           ['scale0_pool[0][0]',
                                                                  'scale1_pool[0][0]',
                                                                  'scale2_pool[0][0]']

 fusion_dense (Dense)           (None, 128)          24704       ['concat_scales[0][0]']

 dropout_6 (Dropout)            (None, 128)          0           ['fusion_dense[0][0]']

 classifier (Dense)             (None, 7)            903         ['dropout_6[0][0]']

==================================================================================================
Total params: 564,935
Trainable params: 564,935
Non-trainable params: 0
__________________________________________________________________________________________________
Epoch 1/20

Epoch 1: val_loss improved from inf to 0.20144, saving model to ms_grs_lstm_model.h5
79/79 - 52s - loss: 0.5893 - accuracy: 0.7940 - val_loss: 0.2014 - val_accuracy: 0.9234 - lr: 0.0010 - 52s/epoch - 655ms/step
Epoch 2/20

Epoch 2: val_loss improved from 0.20144 to 0.09867, saving model to ms_grs_lstm_model.h5
79/79 - 17s - loss: 0.1533 - accuracy: 0.9481 - val_loss: 0.0987 - val_accuracy: 0.9718 - lr: 0.0010 - 17s/epoch - 212ms/step
Epoch 3/20

Epoch 3: val_loss improved from 0.09867 to 0.08282, saving model to ms_grs_lstm_model.h5
79/79 - 17s - loss: 0.0726 - accuracy: 0.9779 - val_loss: 0.0828 - val_accuracy: 0.9741 - lr: 0.0010 - 17s/epoch - 215ms/step
Epoch 4/20

Epoch 4: val_loss improved from 0.08282 to 0.07082, saving model to ms_grs_lstm_model.h5
79/79 - 17s - loss: 0.0964 - accuracy: 0.9680 - val_loss: 0.0708 - val_accuracy: 0.9730 - lr: 0.0010 - 17s/epoch - 218ms/step
Epoch 5/20

Epoch 5: val_loss improved from 0.07082 to 0.06653, saving model to ms_grs_lstm_model.h5
79/79 - 18s - loss: 0.0414 - accuracy: 0.9861 - val_loss: 0.0665 - val_accuracy: 0.9831 - lr: 0.0010 - 18s/epoch - 224ms/step
Epoch 6/20

Epoch 6: val_loss improved from 0.06653 to 0.03100, saving model to ms_grs_lstm_model.h5
79/79 - 18s - loss: 0.0261 - accuracy: 0.9912 - val_loss: 0.0310 - val_accuracy: 0.9944 - lr: 0.0010 - 18s/epoch - 229ms/step
Epoch 7/20

Epoch 7: val_loss did not improve from 0.03100
79/79 - 18s - loss: 0.0148 - accuracy: 0.9950 - val_loss: 0.0645 - val_accuracy: 0.9797 - lr: 0.0010 - 18s/epoch - 233ms/step
Epoch 8/20

Epoch 8: val_loss did not improve from 0.03100
79/79 - 18s - loss: 0.0161 - accuracy: 0.9952 - val_loss: 0.0332 - val_accuracy: 0.9910 - lr: 0.0010 - 18s/epoch - 230ms/step
Epoch 9/20

Epoch 9: val_loss did not improve from 0.03100
79/79 - 18s - loss: 0.0157 - accuracy: 0.9944 - val_loss: 0.0510 - val_accuracy: 0.9910 - lr: 0.0010 - 18s/epoch - 229ms/step
Epoch 10/20

Epoch 10: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.

Epoch 10: val_loss did not improve from 0.03100
79/79 - 18s - loss: 0.0356 - accuracy: 0.9899 - val_loss: 0.0896 - val_accuracy: 0.9707 - lr: 0.0010 - 18s/epoch - 234ms/step
Epoch 11/20

Epoch 11: val_loss improved from 0.03100 to 0.02779, saving model to ms_grs_lstm_model.h5
79/79 - 19s - loss: 0.0164 - accuracy: 0.9958 - val_loss: 0.0278 - val_accuracy: 0.9921 - lr: 5.0000e-04 - 19s/epoch - 239ms/step
Epoch 12/20

Epoch 12: val_loss did not improve from 0.02779
79/79 - 19s - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0377 - val_accuracy: 0.9921 - lr: 5.0000e-04 - 19s/epoch - 240ms/step
Epoch 13/20

Epoch 13: val_loss improved from 0.02779 to 0.02649, saving model to ms_grs_lstm_model.h5
79/79 - 19s - loss: 0.0050 - accuracy: 0.9990 - val_loss: 0.0265 - val_accuracy: 0.9944 - lr: 5.0000e-04 - 19s/epoch - 244ms/step
Epoch 14/20

Epoch 14: val_loss did not improve from 0.02649
79/79 - 19s - loss: 0.0012 - accuracy: 0.9998 - val_loss: 0.0272 - val_accuracy: 0.9944 - lr: 5.0000e-04 - 19s/epoch - 242ms/step
Epoch 15/20

Epoch 15: val_loss improved from 0.02649 to 0.02609, saving model to ms_grs_lstm_model.h5
79/79 - 20s - loss: 0.0016 - accuracy: 0.9998 - val_loss: 0.0261 - val_accuracy: 0.9944 - lr: 5.0000e-04 - 20s/epoch - 253ms/step
Epoch 16/20

Epoch 16: val_loss improved from 0.02609 to 0.02536, saving model to ms_grs_lstm_model.h5
79/79 - 19s - loss: 0.0023 - accuracy: 0.9996 - val_loss: 0.0254 - val_accuracy: 0.9944 - lr: 5.0000e-04 - 19s/epoch - 247ms/step
Epoch 17/20

Epoch 17: val_loss did not improve from 0.02536
79/79 - 19s - loss: 0.0014 - accuracy: 0.9998 - val_loss: 0.0283 - val_accuracy: 0.9944 - lr: 5.0000e-04 - 19s/epoch - 242ms/step
Epoch 18/20

Epoch 18: val_loss improved from 0.02536 to 0.02518, saving model to ms_grs_lstm_model.h5
79/79 - 20s - loss: 0.0019 - accuracy: 0.9994 - val_loss: 0.0252 - val_accuracy: 0.9944 - lr: 5.0000e-04 - 20s/epoch - 250ms/step
Epoch 19/20

Epoch 19: val_loss did not improve from 0.02518
79/79 - 19s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0303 - val_accuracy: 0.9944 - lr: 5.0000e-04 - 19s/epoch - 246ms/step
Epoch 20/20

Epoch 20: val_loss did not improve from 0.02518
79/79 - 19s - loss: 0.0012 - accuracy: 0.9996 - val_loss: 0.0276 - val_accuracy: 0.9944 - lr: 5.0000e-04 - 19s/epoch - 246ms/step
47/47 - 2s - loss: 0.0068 - accuracy: 0.9980 - 2s/epoch - 36ms/step
Test loss: 0.0068  Test acc: 0.9980
47/47 [==============================] - 3s 27ms/step
 r2 score : 0.9956381727376155
Classification report:
              precision    recall  f1-score   support

     bending       1.00      1.00      1.00       217
     jumping       0.99      1.00      1.00       214
     running       1.00      1.00      1.00       205
     sitting       1.00      1.00      1.00       209
       squat       1.00      0.99      1.00       208
    standing       1.00      1.00      1.00       219
     walking       1.00      1.00      1.00       207

    accuracy                           1.00      1479
   macro avg       1.00      1.00      1.00      1479
weighted avg       1.00      1.00      1.00      1479

Confusion matrix:
 [[217   0   0   0   0   0   0]
 [  0 214   0   0   0   0   0]
 [  0   1 204   0   0   0   0]
 [  0   0   0 209   0   0   0]
 [  1   1   0   0 206   0   0]
 [  0   0   0   0   0 219   0]
 [  0   0   0   0   0   0 207]]
 Training history saved as training_history.json
 Batch inference time: 2.7309 sec for 1479 samples
 Average per-sample inference time: 0.001846 sec
 Model size: 6.82 MB
Saved model to ms_grs_lstm_model.h5